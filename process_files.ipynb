{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3ba8bc",
   "metadata": {},
   "source": [
    "## split csv files to qcv format files per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a810270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "# importing required modules\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5af633",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_dir = 'D:/AmeriFlux/'\n",
    "all_zipfiles = glob.glob(zip_dir + \"*.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3b4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = './ameri_sites/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e86e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get those name from the c file \"one_flux\\ONEFlux\\oneflux_steps\\qc_auto\\src\\dataset.c\"  const char *const var_names[]\n",
    "var_names = [\"CO2\",\"H2O\",\"ZL\",\"FC\",\"FC_SSITC_TEST\",\"H\",\"H_SSITC_TEST\",\"LE\",\"LE_SSITC_TEST\",\"USTAR\",\n",
    "\"TR\",\"SB\",\"SC\",\"SLE\",\"SH\",\"P\",\"SW_OUT\",\"SW_IN\",\"NETRAD\",\"SW_DIF\",\"PPFD_IN\",\"APAR\",\"TA\",\"PA\",\"T_CANOPY\",\"T_BOLE\",\"TS\",\"SWC\",\"G\",\n",
    "\"RH\",\"WD\",\"WS\",\"TAU\",\"LW_IN\",\"NEE\",\"VPD\",\"itpVPD\",\"itpSW_IN\",\"itpPPFD_IN\",\"itpTA\",\"itpTS\",\"itpSWC\",\"itpP\",\"itpRH\",\"FETCH_FILTER\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678b6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map columns to qc_auto accepted columns name\n",
    "# like CO2_1_1_1 to CO2\n",
    "def pickup_col(df: pd.DataFrame) ->list:\n",
    "    new_column = dict()\n",
    "    for item in df.columns[2:]:\n",
    "        if item in var_names:\n",
    "            new_column[item] = item\n",
    "        else:\n",
    "            sub_items = item.split('_')\n",
    "            key0 = sub_items[0]\n",
    "            if key0 in var_names:\n",
    "                if key0 not in new_column.keys():\n",
    "                    new_column[key0] = item\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                key1 = key0 + '_'+ sub_items[1]  # According to var_name, there only have xx_xxx format besides XX_SSITC_TEST items\n",
    "                if key1 in var_names:\n",
    "                    if key1 not in new_column.keys():\n",
    "                        new_column[key1] = item\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608ec1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split rows per years\n",
    "# return year list and start and end position for each year\n",
    "def split_records(src_data: pd.DataFrame) -> (list, list, list):\n",
    "    years = []\n",
    "    start_pos = []\n",
    "    end_pos = []\n",
    "\n",
    "    start_year = ''\n",
    "    rows = src_data['TIMESTAMP_END'].count()\n",
    "    for idx in range(rows):\n",
    "        if start_year == '':\n",
    "            start_year = src_data.iloc[idx]['TIMESTAMP_START'][:4]\n",
    "            years.append(start_year)\n",
    "            start_pos.append(idx)\n",
    "        else:\n",
    "            if start_year == src_data.iloc[idx]['TIMESTAMP_START'][:4]:\n",
    "                _end = idx\n",
    "            else:\n",
    "                end_pos.append(_end)\n",
    "                start_year = src_data.iloc[idx]['TIMESTAMP_START'][:4]\n",
    "                years.append(start_year)\n",
    "                start_pos.append(idx)\n",
    "\n",
    "    end_pos.append(_end)\n",
    "    \n",
    "    return years, start_pos, end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcee6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vpd(row):\n",
    "    ta = row['TA']\n",
    "    rh = row['RH']\n",
    "    if ta == -9999 or rh == -9999:\n",
    "        vpd =  -9999\n",
    "    else:\n",
    "        es = 0.6108 * np.exp((17.27*ta)/(ta+237.3)) * 1000\n",
    "        ea = es * rh / 100.0\n",
    "        vpd = (es - ea) /100.0\n",
    "\n",
    "    return round(vpd,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "646219d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qcv_files(df: pd.DataFrame,site_info: pd.DataFrame, dst_name:str, site_name: str, record_interval: str):\n",
    "    \n",
    "    new_columns = pickup_col(df)\n",
    "    \n",
    "    header = ['TIMESTAMP_START','TIMESTAMP_END']\n",
    "    # revert key value position\n",
    "    selected_cols = dict()\n",
    "    for key,value in new_columns.items():\n",
    "        selected_cols[value] = key\n",
    "    \n",
    "    header += list(selected_cols.keys())\n",
    "    \n",
    "    years, start_pos, end_pos = split_records(df)\n",
    "    \n",
    "    #site_name = 'US-Ne2'\n",
    "    for year, start, end in zip(years, start_pos, end_pos):\n",
    "        # file name format is like US-ARc_qcv_2005.csv\n",
    "        file_name = dst_name + site_name + '_qcv_'+ year + '.csv'\n",
    "        _data = df[header].iloc[start: end+1].rename(columns=selected_cols)\n",
    "        _data['VPD'] = _data.apply (lambda row: create_vpd(row) , axis=1)\n",
    "        _data.to_csv(file_name,index=False)\n",
    "        \n",
    "        file = open(file_name,'r')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        file = open(file_name,'w')\n",
    "        file.write('site,{}\\n'.format(site_name))\n",
    "        file.write('year,{}\\n'.format(year))\n",
    "        file.write('lat,{}\\n'.format(site_info['Latitude'][0]))\n",
    "        file.write('lon,{}\\n'.format(site_info['Longitude'][0]))\n",
    "        file.write('timezone,{}\\n'.format(site_info['UTC'][0]))\n",
    "        file.write('htower,{},{}\\n'.format(_data.iloc[0]['TIMESTAMP_END'], 5))\n",
    "        file.write('timeres,{}\\n'.format(record_interval))\n",
    "        file.write('sc_negl,1\\n')\n",
    "        file.write('notes,202305041205 qc visual comparison SY\\n')\n",
    "        file.write(text)\n",
    "        file.close()\n",
    "        \n",
    "        print('...... Create file {} successful.'.format(file_name))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85310d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elev</th>\n",
       "      <th>UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AR-TF1</td>\n",
       "      <td>-54.9733</td>\n",
       "      <td>-66.7335</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR-TF2</td>\n",
       "      <td>-54.8269</td>\n",
       "      <td>-68.4549</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR-CST</td>\n",
       "      <td>-7.9682</td>\n",
       "      <td>-38.3842</td>\n",
       "      <td>468.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR-Npw</td>\n",
       "      <td>-16.4980</td>\n",
       "      <td>-56.4120</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-ARB</td>\n",
       "      <td>52.6950</td>\n",
       "      <td>-83.9452</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>US-xUK</td>\n",
       "      <td>39.0404</td>\n",
       "      <td>-95.1921</td>\n",
       "      <td>335.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>US-xUN</td>\n",
       "      <td>46.2339</td>\n",
       "      <td>-89.5373</td>\n",
       "      <td>518.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>US-xWD</td>\n",
       "      <td>47.1282</td>\n",
       "      <td>-99.2414</td>\n",
       "      <td>579.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>US-xWR</td>\n",
       "      <td>45.8205</td>\n",
       "      <td>-121.9519</td>\n",
       "      <td>407.0</td>\n",
       "      <td>-8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>US-xYE</td>\n",
       "      <td>44.9535</td>\n",
       "      <td>-110.5391</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    site_id  Latitude  Longitude    Elev  UTC\n",
       "0    AR-TF1  -54.9733   -66.7335    40.0 -3.0\n",
       "1    AR-TF2  -54.8269   -68.4549    60.0 -3.0\n",
       "2    BR-CST   -7.9682   -38.3842   468.0 -3.0\n",
       "3    BR-Npw  -16.4980   -56.4120   120.0 -4.0\n",
       "4    CA-ARB   52.6950   -83.9452    90.0 -5.0\n",
       "..      ...       ...        ...     ...  ...\n",
       "328  US-xUK   39.0404   -95.1921   335.0 -6.0\n",
       "329  US-xUN   46.2339   -89.5373   518.0 -6.0\n",
       "330  US-xWD   47.1282   -99.2414   579.0 -6.0\n",
       "331  US-xWR   45.8205  -121.9519   407.0 -8.0\n",
       "332  US-xYE   44.9535  -110.5391  2116.0 -7.0\n",
       "\n",
       "[333 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_site = pd.read_csv('AmeriFlux_siteinfo.csv')\n",
    "pd_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98ac04b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process zip file D:/AmeriFlux\\AMF_AR-TF1_BASE-BADM_2-5.zip........\n",
      "...... Create file ./ameri_sites/AR-TF1/01_qc_visual/qcv_files/AR-TF1_qcv_2016.csv successful.\n",
      "...... Create file ./ameri_sites/AR-TF1/01_qc_visual/qcv_files/AR-TF1_qcv_2017.csv successful.\n",
      "...... Create file ./ameri_sites/AR-TF1/01_qc_visual/qcv_files/AR-TF1_qcv_2018.csv successful.\n"
     ]
    }
   ],
   "source": [
    "for zip_file in all_zipfiles:\n",
    "    file_name = zip_file.split('.')[0]\n",
    "    site_name = file_name.split('_')[1]\n",
    "    site_info = pd_site[pd_site['site_id'] == site_name]\n",
    "    \n",
    "    dst_name = dst_dir + site_name + '/01_qc_visual/qcv_files/'\n",
    "    if not os.path.exists(dst_name):\n",
    "        os.makedirs(dst_name)\n",
    "\n",
    "    with ZipFile(zip_file, 'r') as zip_folder:\n",
    "        file_list = zip_folder.namelist()\n",
    "        if len(file_list) > 1:\n",
    "            for _file in file_list:\n",
    "                name_split = _file.split('.')\n",
    "\n",
    "                if name_split[1] == 'csv':\n",
    "                    df = pd.read_csv(zip_folder.open(_file),dtype={'TIMESTAMP_START':str, 'TIMESTAMP_END':str},skiprows=2)\n",
    "                    if df.iloc[0]['TIMESTAMP_END'][-4:] == '0030':\n",
    "                        record_interval = 'halfhourly'\n",
    "                    else:\n",
    "                        record_interval = 'hourly'\n",
    "                        \n",
    "                    print('Process zip file {}........'.format(zip_file))\n",
    "                    create_qcv_files(df,site_info, dst_name, site_name, record_interval)\n",
    "                    \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88159ede",
   "metadata": {},
   "source": [
    "### Below code for easy debeuggin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = 'US-Ne2/AMF_US-Ne2_BASE_HR_9-5.csv'\n",
    "src_data = pd.read_csv(src_file, dtype={'TIMESTAMP_START':str, 'TIMESTAMP_END':str},skiprows=2)\n",
    "src_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe698c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data.iloc[0]['TIMESTAMP_END']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b492f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = dict()\n",
    "for item in df.columns[2:]:\n",
    "    if item in var_names:\n",
    "        new_column[item] = item\n",
    "    else:\n",
    "        sub_items = item.split('_')\n",
    "        key0 = sub_items[0]\n",
    "        if key0 in var_names:\n",
    "            if key0 not in new_column.keys():\n",
    "                new_column[key0] = item\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            key1 = key0 + '_'+ sub_items[1]  # According to var_name, there only have xx_xxx format besides XX_SSITC_TEST items\n",
    "            if key1 in var_names:\n",
    "                if key1 not in new_column.keys():\n",
    "                    new_column[key1] = item\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['TIMESTAMP_START','TIMESTAMP_END']\n",
    "selected_cols = dict()\n",
    "for key,value in new_column.items():\n",
    "    selected_cols[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "header += list(selected_cols.keys())\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = src_data['TIMESTAMP_END'].count()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data.iloc[1]['TIMESTAMP_START'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8525a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "start_pos = []\n",
    "end_pos = []\n",
    "\n",
    "start_year = ''\n",
    "\n",
    "for idx in range(rows):\n",
    "    if start_year == '':\n",
    "        start_year = src_data.iloc[idx]['TIMESTAMP_START'][:4]\n",
    "        years.append(start_year)\n",
    "        start_pos.append(idx)\n",
    "    else:\n",
    "        if start_year == src_data.iloc[idx]['TIMESTAMP_START'][:4]:\n",
    "            _end = idx\n",
    "        else:\n",
    "            end_pos.append(_end)\n",
    "            start_year = src_data.iloc[idx]['TIMESTAMP_START'][:4]\n",
    "            years.append(start_year)\n",
    "            start_pos.append(idx)\n",
    "            \n",
    "end_pos.append(_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "years, start_pos, end_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c895230",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_name = 'US-Ne2'\n",
    "for year, start, end in zip(years, start_pos, end_pos):\n",
    "    # file name format is like US-ARc_qcv_2005.csv\n",
    "    file_name = site_name + '_qcv_'+ year + '.csv'\n",
    "    _data = src_data[header].iloc[start: end+1].rename(columns=selected_cols)\n",
    "    _data.to_csv('./ameri_sites/US-Ne2/'+ file_name,float_format='%.5f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1032bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = src_data[header].iloc[100: 200+1].rename(columns=selected_cols)\n",
    "_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp['TA'] = np.random.rand(101)\n",
    "_tmp['RH'] = np.random.rand(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vpd(row):\n",
    "    ta = row['TA']\n",
    "    rh = row['RH']\n",
    "    if ta == -9999 or rh == -9999:\n",
    "        vpd =  -9999\n",
    "    else:\n",
    "        es = 0.6108 * np.exp((17.27*ta)/(ta+237.3)) * 1000\n",
    "        ea = es * rh / 100.0\n",
    "        vpd = (es - ea) /100.0\n",
    "\n",
    "    return vpd\n",
    "_tmp['VPD'] = _tmp.apply (lambda row: create_vpd(row) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi",
   "language": "python",
   "name": "hsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
